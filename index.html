<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Valentin Thomas</title>
  
  <meta name="author" content="Valentin Thomas">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Valentin Thomas</name>
              </p>
              <p>I recently graduated from my PhD at <a href="https://mila.quebec/en">Mila</a>, where I worked on Reinforcement Learning and Deep Learning. <span class="highlight">Warning</span> this site is still under construction, my linked CV may be more up to date.
              </p>
              <p style="text-align:center">
                <a href="mailto:vltn.thomas@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Resume_Valentin_THOMAS.pdf">CV</a> &nbsp/&nbsp
                <a href="data/VTHOMAS-bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=XRhKEGMAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/lanternol">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/valthom/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile_pic_vt.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_pic_vt_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in reinforcement learning, deep learning and optimization. I have worked on unsupervised RL, planning, generalization in deep learning and optimization aspects of reinforcement learning. Representative papers are <span class="highlight">highlighted</span>. Stars * indicate first authorship.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/rmt_td2.png" alt="rmt_td" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
		  <a href="https://openreview.net/pdf?id=g-H3oNARs2" id="rmt_td">
                <papertitle>On the role of overparameterization in off-policy Temporal Difference learning with linear function approximation</papertitle>
              </a>
              <br>
              <strong>Valentin Thomas*</strong>
              <br>
	      <conference>NeurIPS 2022</conference>
              <br>
              <p></p>
              <p> We study the role of overparameterization in Temporal Difference (TD) learning and how it affects optimization. For this, we analyze the spectrum of the Temporal Difference operator when using random features and with some assumptions of the Markov transition kernel.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/baselines_mei.png" alt="baselines_mei" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
		     <a href="https://openreview.net/pdf?id=XzeTJBq1Ce2" id="mei_baselines">
                <papertitle>The Role of Baselines in Policy Optimization</papertitle>
              </a>
              <br>
              Jincheng Mei*, Wesley Chung, <strong>Valentin Thomas</strong>, Bo Dai, Csaba Szepesvari, Dale Schuurmans
              <br>
	      <conference>NeurIPS 2022</conference>
              <br>
              <p></p>
              <p>Using value function baselines in on-policy stochastic natural policy gradients help achieve convergence toward globally optimal policy by reducing update aggressiveness rather than variance.</p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/target.png" alt="target" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
	     <a href="https://arxiv.org/abs/2106.02613" id="target">
                <papertitle>Bridging the Gap Between Target Networks and Functional Regularization</papertitle>
              </a>
              <br>
	      Alexandre Pich√©*, <strong>Valentin Thomas*</strong>, Joseph Marino, Rafael Pardinas, Gian Maria Marconi, Christopher Pal, Mohammad Emtiyaz Khan
              <br>
	      <conference>TMLR 2023</conference>
	      <br>
	      <workshop>NeurIPS 2021 DeepRL workshop</workshop>
              <br>
              <p></p>
	      <p>We analyze the implicit regularization performed by using <em>Target Networks</em> and show that, surprisingly, it can unstabilize TD. We propose a theoretically grounded alternative method, <em>Functional Regularization</em>, which alleviates these theoretical issues and performs well empirically.</p>
            </td>
          </tr>
	  
          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/baselines.png" alt="baselines" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
	     <a href="https://arxiv.org/abs/2008.13773" id="baselines">
                <papertitle>Beyond variance reduction: Understanding the true impact of baselines on policy optimization</papertitle>
              </a>
              <br>
	      <strong>Valentin Thomas*</strong>, Wesley Chung*, Marlos C. Machado, Nicolas Le Roux
              <br>
              <conference>ICML 2021</conference>
              <br>
	      <a href="http://mcmachado.info/?p=328">blog post</a>/<a href="https://slideslive.com/38959283/beyond-variance-reduction-understanding-the-true-impact-of-baselines-on-policy-optimization">ICML talk</a>
              <p></p>
              <p>We show empirically and theoretically that despite common wisdom, baselines in policy gradient optimization have an effect beyond variance reduction and can impact convergence.</p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/hfc.png" alt="hfc" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
	     <a href="https://arxiv.org/abs/1906.07774" id="hfc">
                <papertitle>On the interplay between noise and curvature and its effect on optimization and generalization</papertitle>
              </a>
              <br>
	      <strong>Valentin Thomas*</strong>, Fabian Pedregosa, Bart van Merri√´nboer, Pierre-Antoine Mangazol, Yoshua Bengio, Nicolas Le Roux
              <br>
	      <conference>AISTATS 2020</conference>
              <br>
	      <workshop>Oral talk at the 2020 Workshop on theory of deep learning at
		      the Institute for Advanced Studies, Princeton </workshop>
              <br>
	      <a href="https://slideslive.com/38930270/on-the-interplay-between-noise-and-curvature-and-its-effect-on-optimization-and-generalization?ref=speaker-35777">AISTATS talk</a>
              <p></p>
              <p>We show how the interplay between the local curvature of the loss (the hessian) and the local gradient noise (the uncentered gradient covariance) can impact optimization and generalization in neural networks.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/pslt.png" alt="smcp" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
	     <a href="https://eringrant.github.io/spirl/2019/camera-ready/spirl_camera-ready_38.pdf" id="pslt">
                <papertitle>Planning with Latent Simulated Trajectories </papertitle>
              </a>
              <br>
	      Alexandre Pich√©, <strong>Valentin Thomas</strong>, Cyril
Ibrahim, Yoshua Bengio, Julien Cornebise and Chris Pal              <br>
              <workshop>ICLR 2019 Workshop on Structure and Priors in Reinforcement Learning</workshop>
	      <br>
	      <!--<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> -->
              <p></p>
              <p>Extension of our work "Probabilistic Planning with Sequential Monte Carlo methods" by treating the trajectory as a latent variable and using an EM algorithm.</p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/smcp.png" alt="smcp" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
	     <a href="https://openreview.net/forum?id=ByetGn0cYX" id="smcp">
                <papertitle>Probabilistic Planning with Sequential Monte Carlo methods</papertitle>
              </a>
              <br>
	      <strong>Valentin Thomas*</strong>, Alexandre Pich√©*, Cyril
Ibrahim, Yoshua Bengio and Chris Pal              <br>
	      <conference>ICLR 2019</conference>
              <br>
              <workshop>Contributed talk at NeurIPS 2018 workshop Infer to Control</workshop>
	      <br>
	      <!--<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> -->
              <p></p>
              <p>Leveraging control as inference and Sequential Monte Carlo methods, we propose a probabilistic planning algorithm.</p>
            </td>
          </tr>

 <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/disentangling_world.png" alt="smcp" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
	     <a href="https://arxiv.org/abs/1802.09484" id="disentangling_world">
                <papertitle>Disentangling the independently controllable factors of variation by interacting with the world</papertitle>
              </a>
              <br>
	      <strong>Valentin Thomas*</strong>, Emmanuel Bengio*, William Fedus*, Jules Pondard, Philippe Beaudoin, Hugo Larochelle, Joelle Pineau,
Doina Precup and Yoshua Bengio <br>
<workshop>Oral at NeurIPS 2017 workshop on Learning Disentangled Representations: from
Perception to Control
</workshop>
	      <br>
	      <!--<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> -->
              <p></p>
	      <p>We draw a connection between mutual information and the intrinsic reward function (through the Donsker-Varadhan representation of the Kullback-Leibler divergence) used for learning jointly options/factors and latent representations in <em>Independently Controllable Factors</em>.</p>
            </td>
          </tr>

 <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/icf_grid.png" alt="icf_grid" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
	     <a href="https://arxiv.org/abs/1708.01289" id="icf">
                <papertitle>Independently Controllable Factors</papertitle>
              </a>
              <br>
	      <strong>Valentin Thomas*</strong>, Jules Pondard*, Emmanuel Bengio*, Marc Sarfati, Philippe Beaudoin, Marie-Jean Meurs, Joelle Pineau, Doina Precup, Yoshua Bengio<br>
<workshop> Presented at the Montreal AI Symposium 2017
</workshop>
	      <br>
	      <!--<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> -->
              <p></p>
	      <p>This work is a finalized version of <em>Independently Controllable Features</em> where the policies and factors are now embedded in a contiuous space. We demonstrate how one can use the features learnt.</p>
            </td>
          </tr>
 <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/icf_tabular.png" alt="icf_tabular" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
	     <a href="https://arxiv.org/abs/1708.01289" id="icf">
                <papertitle>Independently Controllable Features</papertitle>
              </a>
              <br>
	      Emmanuel Bengio*, <strong>Valentin Thomas</strong>, Joelle Pineau, Doina Precup, Yoshua Bengio<br>
<conference> RLDM 2017
</conference>
	      <br>
	      <!--<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> -->
              <p></p>
	      <p>We propose a way to learn jointly a set of discrete policies each affecting a component of the latent state representation for unsupervised reinforcement learning. We hypothesize that this process discovers <em>controllable factors of variation</em> in the world as well as how to <em>control</em> them.</p>
            </td>
          </tr>

 <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/decoupling.png" alt="decoupling" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
	     <a href="https://openreview.net/forum?id=BygR79WfWm" id="decoupling">
                <papertitle>Decoupling Backpropagation using Constrained Optimization Methods</papertitle>
              </a>
              <br>
	      <strong>Valentin Thomas*</strong>, Akhilesh Gotmare*,
Johanni Brea and Martin Jaggi<br>
<workshop>In ICML 2018 workshop on Efficent Credit Assignement </workshop>
	      <br>
	      <!--<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> -->
              <p></p>
              <p>We propose BlockProp which lets one train deep neural networks in model parallel fashion, where parts of the model may reside on different devices (GPUs).</p>
            </td>
          </tr>

 <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/qbits.png" alt="qbits" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
	     <a href="https://valthom.github.io/data/rapportS3-Valentin-THOMAS.pdf" id="qbits">
                <papertitle>Preserving the entanglement of two qubits with feedback control</papertitle>
              </a>
              <br>
	      <strong>Valentin Thomas*</strong>, Pierre Rouchon<br>
<em>Report for a research semester in 2014 (in french)</em>
	      <br>
	      <!--<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> -->
              <p></p>
              <p>This research project was about designing a feeback control loop using an electromagnetic field to preserve the entanglement of two qbits. This is necessary as because of quantum decoherence the entanglement tends to vanish which is a major issue in developping quantum computer hardware. We proposed a simple Lyapunov-based feedback control loop.</p>
            </td>
          </tr>

        </tbody></table>
              <heading>Experience</heading>
	      <p>Here you can find the internships I have done during my MSc at Mines Paris and at Ecole Normale Superi√©ure Paris-Saclay then during my PhD at University of Montreal.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <td style="padding:20px;width:100%;vertical-align:middle;text-align:center">
              <img src="images/timeline_work.png" alt="rmt_td" width="640" style="border-style: none">
            </td>
          </tr>

			<!--	
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
              <br>
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
              <br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr>
					

          <tr>
            <td align="center" style="padding:20px;width:25%;vertical-align:middle">
							<heading>Basically <br> Blog Posts</heading>
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
              <br>
              <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
              <br>
              <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
            </td>
          </tr>
					
					
        </tbody></table>-->
			
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
	      Website template from <a = href="http://jonbarron.info"> Jon Barron</a> (<a href="https://github.com/jonbarron/jonbarron_website">source code</a>).
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
