<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Valentin Thomas</title>
  
  <meta name="author" content="Valentin Thomas">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Valentin Thomas</name>
              </p>
              <p>I am a last year PhD student at  <a href="https://mila.quebec/en">Mila</a>, where I work on Reinforcement Learning and Deep Learning. <span class="highlight">Warning</span> this site is still under construction, my linked CV may be more up to date.
              </p>
              <p style="text-align:center">
                <a href="mailto:vltn.thomas@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Resume_Valentin_THOMAS.pdf">CV</a> &nbsp/&nbsp
                <a href="data/VTHOMAS-bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=XRhKEGMAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/lanternol">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/valthom/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile_pic_vt.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_pic_vt_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in reinforcement learning, deep learning and optimization. I have worked on unsupervised RL, planning, generalization in deep learning and optimization aspects of reinforcement learning. Representative papers are <span class="highlight">highlighted</span>. Stars * indicate first authorship.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/rmt_td.png" alt="rmt_td" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
		    <!-- <a href="https://arxiv.org/abs/" id="rmt_td"> -->
                <papertitle>On the role of overparameterization in off-policy Temporal Difference learning with linear function approximation</papertitle>
              </a>
              <br>
              <strong>Valentin Thomas</strong>
              <br>
              <em>NeurIPS</em>, 2022
              <br>
              <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> /
              <p></p>
              <p>We propose an analysis of the spectrum of the Temporal Difference operator for value estimation when using random features.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/baselines_mei.png" alt="baselines_mei" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
		    <!-- <a href="https://arxiv.org/abs/" id="rmt_td"> -->
                <papertitle>The Role of Baselines in Policy Optimization</papertitle>
              </a>
              <br>
              Jincheng Mei*, Wesley Chung, <strong>Valentin Thomas</strong>, Bo Dai, Csaba Szepesvari, Dale Schuurmans
              <br>
              <em>NeurIPS</em>, 2022
              <br>
	      <!--<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> --> /
              <p></p>
              <p>Using value function baselines in on-policy stochastic natural policy gradients help achieve convergence toward globally optimal policy by reducing update aggressiveness rather than variance.</p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/target.png" alt="target" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
	     <a href="https://arxiv.org/abs/2106.02613" id="target">
                <papertitle>Beyond Target Networks: Improving Deep Q-learning with Functional Regularization</papertitle>
              </a>
              <br>
	      Alexandre Pich√©*, <strong>Valentin Thomas*</strong>, Joseph Marino, Gian Maria Marconi, Christopher Pal, Mohammad Emtiyaz Khan
              <br>
              <em>Preprint</em>, 2022
              <br>
	      <!--<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> --> /
              <p></p>
	      <p>We analyze the implicit regularization performed by using <em>Target Networks</em> and show that, surprisingly, it can unstabilize TD. We propose a theoretically grounded alternative method, <em>Functional Regularization</em> which alleviates these theoretical issues and performs well empirically.</p>
            </td>
          </tr>
	  
          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/baselines.png" alt="baselines" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
	     <a href="https://arxiv.org/abs/2008.13773" id="baselines">
                <papertitle>Beyond variance reduction: Understanding the true impact of baselines on policy optimization</papertitle>
              </a>
              <br>
	      Wesley Chung*, <strong>Valentin Thomas*</strong>, Marlos C. Machado, Nicolas Le Roux
              <br>
              <em>ICML</em>, 2021
              <br>
	      <!--<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> --> /
              <p></p>
              <p>We show empirically and theoretically that despite common wisdom, baselines in policy gradient optimization have an effect beyond variance reduction and have an impact on convergence.</p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/hfc.png" alt="hfc" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
	     <a href="https://arxiv.org/abs/1906.07774" id="hfc">
                <papertitle>On the interplay between noise and curvature and its effect on optimization and generalization</papertitle>
              </a>
              <br>
	      <strong>Valentin Thomas*</strong>, Fabian Pedregosa, Bart van Merri√´nboer, Pierre-Antoine Mangazol, Yoshua Bengio, Nicolas Le Roux
              <br>
              <em>AISTATS</em>, 2020
              <br>
	      <em>Oral talk at the 2020 Workshop on theory of deep learning at
		      the Institute for Advanced Studies, Princeton </em>
              <br>
	      <!--<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> --> /
              <p></p>
              <p>We show how the interplay between the local curvature of the loss (the hessian) and the local gradient noise (the uncentered gradient covariance) can impact optimization and generalization in neural networks.</p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/smcp.png" alt="smcp" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
	     <a href="https://openreview.net/forum?id=ByetGn0cYX" id="smcp">
                <papertitle>Probabilistic Planning with Sequential Monte Carlo methods</papertitle>
              </a>
              <br>
	      <strong>Valentin Thomas*</strong>, Alexandre Pich√©*, Cyril
Ibrahim, Yoshua Bengio and Chris Pal              <br>
              <em>ICLR</em>, 2019
              <br>
              <em>Contributed talk at NeurIPS 2018 workshop Infer to Control</em>
	      <br>
	      <!--<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> --> /
              <p></p>
              <p>Leveraging control as inference and Sequential Monte Carlo methods, we propose a probabilistic planning algorithm.</p>
            </td>
          </tr>

 <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/disentangling_world.png" alt="smcp" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
	     <a href="https://arxiv.org/abs/1802.09484" id="disentangling_world">
                <papertitle>Disentangling the independently controllable factors of variation by interacting with the world</papertitle>
              </a>
              <br>
	      <strong>Valentin Thomas*</strong>, Emmanuel Bengio*, William Fedus*, Jules Pondard, Philippe Beaudoin, Hugo Larochelle, Joelle Pineau,
Doina Precup and Yoshua Bengio <br>
              <em>Oral at NeurIPS 2017 workshop on Learning Disentangled Representations: from
Perception to Control
</em>
	      <br>
	      <!--<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> --> /
              <p></p>
              <p>We propose a mutual information based reward function for learning jointly options/factors and latent represention in the context of unsupervised reinforcement learning..</p>
            </td>
          </tr>

        </tbody></table>

			<!--	
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
              <br>
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
              <br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr>
					

          <tr>
            <td align="center" style="padding:20px;width:25%;vertical-align:middle">
							<heading>Basically <br> Blog Posts</heading>
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
              <br>
              <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
              <br>
              <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
            </td>
          </tr>
					
					
        </tbody></table>-->
			
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
	      Website template from <a = href="http://jonbarron.info"> Jon Barron</a> (<a href="https://github.com/jonbarron/jonbarron_website">source code</a>).
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
